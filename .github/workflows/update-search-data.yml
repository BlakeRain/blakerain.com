name: Update Search Data

on:
  schedule:
    - cron: 0 * * * *
  workflow_dispatch:

jobs:
  update-search-data:
    if: ${{ github.repository == 'BlakeRain/blakerain.com' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout the repository
        uses: actions/checkout@v2
        with:
          fetch-depth: 0
      - name: Setup Python
        uses: actions/setup-python@v2
      - name: Install requirements
        uses: pip3 install -r requirements.txt
      - name: Build the search data
        env:
          DOMAIN: blakerain.com
          API_KEY: ${{ secrets.GHOST_CONTENT_API_KEY }}
        run: |
          python3 search/update-search.py
      - name: Deploy to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.DEPLOYMENT_AWS_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.DEPLOYMENT_AWS_SECRET }}
        run: |
          aws s3 sync --region eu-west-1 ./search.bin s3://s3.blakerain.com/data/search.bin
